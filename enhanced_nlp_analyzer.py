"""
Enhanced NLP Analysis System for KrakenBot
Provides real-time natural language insights and strategy recommendations
"""

import json
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from pathlib import Path
import re
from dataclasses import dataclass, asdict

@dataclass
class TradingInsight:
    """Represents a trading insight generated by NLP analysis."""
    timestamp: datetime
    insight_type: str  # 'opportunity', 'warning', 'trend', 'performance'
    priority: str  # 'low', 'medium', 'high', 'critical'
    title: str
    description: str
    actionable_items: List[str]
    confidence: float
    data_sources: List[str]

@dataclass
class PerformanceAnalysis:
    """Performance analysis with natural language explanations."""
    period: str
    total_return: float
    win_rate: float
    avg_profit_per_trade: float
    max_drawdown: float
    sharpe_ratio: float
    summary: str
    strengths: List[str]
    weaknesses: List[str]
    recommendations: List[str]

class EnhancedNLPAnalyzer:
    """Advanced NLP analysis for trading insights and recommendations."""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.insights_history = []
        self.performance_cache = {}
        
        # Trading patterns and their descriptions
        self.pattern_descriptions = {
            'bull_run': "Strong upward price movement with increasing volume",
            'bear_market': "Sustained downward trend with high selling pressure",
            'consolidation': "Price moving sideways within a defined range",
            'breakout': "Price breaking above resistance with strong volume",
            'breakdown': "Price falling below support with increased selling",
            'reversal': "Trend change from bullish to bearish or vice versa",
            'volatility_spike': "Sudden increase in price volatility",
            'volume_surge': "Unusual increase in trading volume"
        }
        
        # Risk level descriptions
        self.risk_descriptions = {
            'LOW': "Conservative approach with minimal downside risk",
            'MEDIUM': "Balanced risk-reward with moderate volatility exposure",
            'HIGH': "Aggressive strategy with significant profit potential but higher risk",
            'CRITICAL': "Extreme risk conditions requiring immediate attention"
        }
    
    def analyze_trading_session(self, session_dir: str) -> Dict:
        """Comprehensive NLP analysis of a trading session."""
        session_path = Path(session_dir)
        
        if not session_path.exists():
            return {'error': f'Session directory not found: {session_dir}'}
        
        # Load session data
        session_data = self._load_session_data(session_path)
        
        if not session_data:
            return {'error': 'No valid session data found'}
        
        # Generate comprehensive analysis
        analysis = {
            'session_id': session_path.name,
            'analysis_timestamp': datetime.now().isoformat(),
            'session_summary': self._generate_session_summary(session_data),
            'performance_analysis': asdict(self._analyze_performance(session_data)),
            'trading_patterns': self._identify_trading_patterns(session_data),
            'market_insights': self._generate_market_insights(session_data),
            'risk_assessment': self._assess_risk_factors(session_data),
            'strategic_recommendations': self._generate_strategic_recommendations(session_data),
            'key_insights': self._extract_key_insights(session_data),
            'narrative_summary': self._create_narrative_summary(session_data)
        }
        
        return analysis
    
    def _load_session_data(self, session_path: Path) -> Dict:
        """Load all relevant data from a trading session."""
        data = {}
        
        # Load portfolio history
        portfolio_file = session_path / "portfolio_history.json"
        if portfolio_file.exists():
            with open(portfolio_file, 'r') as f:
                data['portfolio_history'] = json.load(f)
        
        # Load trades
        trades_file = session_path / "trades.json"
        if trades_file.exists():
            with open(trades_file, 'r') as f:
                data['trades'] = json.load(f)
        else:
            data['trades'] = []
        
        # Load performance summary
        performance_file = session_path / "performance_summary.json"
        if performance_file.exists():
            with open(performance_file, 'r') as f:
                data['performance_summary'] = json.load(f)
        
        # Load price history
        price_file = session_path / "price_history.json"
        if price_file.exists():
            with open(price_file, 'r') as f:
                data['price_history'] = json.load(f)
        
        return data
    
    def _generate_session_summary(self, session_data: Dict) -> str:
        """Generate a natural language summary of the trading session."""
        portfolio_history = session_data.get('portfolio_history', [])
        trades = session_data.get('trades', [])
        performance = session_data.get('performance_summary', {})
        
        if not portfolio_history:
            return "No trading activity recorded during this session."
        
        # Calculate session metrics
        start_time = datetime.fromisoformat(portfolio_history[0]['timestamp'].replace('Z', '+00:00'))
        end_time = datetime.fromisoformat(portfolio_history[-1]['timestamp'].replace('Z', '+00:00'))
        duration = end_time - start_time
        
        initial_value = portfolio_history[0]['portfolio_value']
        final_value = portfolio_history[-1]['portfolio_value']
        total_return = ((final_value - initial_value) / initial_value) * 100
        
        num_trades = len(trades)
        
        # Generate summary
        summary_parts = []
        
        # Duration and basic stats
        hours = duration.total_seconds() / 3600
        summary_parts.append(f"Trading session lasted {hours:.1f} hours with {num_trades} trades executed.")
        
        # Performance summary
        if total_return > 0:
            summary_parts.append(f"The session was profitable with a {total_return:.3f}% return, "
                                f"growing the portfolio from ${initial_value:.2f} to ${final_value:.2f}.")
        elif total_return < 0:
            summary_parts.append(f"The session resulted in a {abs(total_return):.3f}% loss, "
                                f"with portfolio value declining from ${initial_value:.2f} to ${final_value:.2f}.")
        else:
            summary_parts.append(f"The session broke even with minimal portfolio value change.")
        
        # Trading frequency
        if num_trades > 0:
            trades_per_hour = num_trades / max(hours, 1)
            if trades_per_hour > 2:
                summary_parts.append(f"High trading frequency of {trades_per_hour:.1f} trades per hour indicates active market conditions.")
            elif trades_per_hour < 0.5:
                summary_parts.append(f"Low trading frequency of {trades_per_hour:.1f} trades per hour suggests stable market conditions.")
            else:
                summary_parts.append(f"Moderate trading frequency of {trades_per_hour:.1f} trades per hour shows balanced market activity.")
        
        return " ".join(summary_parts)
    
    def _analyze_performance(self, session_data: Dict) -> PerformanceAnalysis:
        """Detailed performance analysis with explanations."""
        portfolio_history = session_data.get('portfolio_history', [])
        trades = session_data.get('trades', [])
        performance = session_data.get('performance_summary', {})
        
        if not portfolio_history:
            return PerformanceAnalysis(
                period="No data",
                total_return=0,
                win_rate=0,
                avg_profit_per_trade=0,
                max_drawdown=0,
                sharpe_ratio=0,
                summary="Insufficient data for performance analysis",
                strengths=[],
                weaknesses=["No trading data available"],
                recommendations=["Execute trades to generate performance data"]
            )
        
        # Calculate metrics
        initial_value = portfolio_history[0]['portfolio_value']
        final_value = portfolio_history[-1]['portfolio_value']
        total_return = ((final_value - initial_value) / initial_value) * 100
        
        # Calculate win rate and average profit
        profitable_trades = 0
        total_profit = 0
        
        for trade in trades:
            profit = trade.get('profit', 0)
            if profit > 0:
                profitable_trades += 1
            total_profit += profit
        
        win_rate = (profitable_trades / len(trades) * 100) if trades else 0
        avg_profit_per_trade = total_profit / len(trades) if trades else 0
        
        # Calculate maximum drawdown
        portfolio_values = [p['portfolio_value'] for p in portfolio_history]
        peak = portfolio_values[0]
        max_drawdown = 0
        
        for value in portfolio_values:
            if value > peak:
                peak = value
            drawdown = (peak - value) / peak * 100
            max_drawdown = max(max_drawdown, drawdown)
        
        # Calculate Sharpe ratio (simplified)
        returns = []
        for i in range(1, len(portfolio_values)):
            ret = (portfolio_values[i] - portfolio_values[i-1]) / portfolio_values[i-1]
            returns.append(ret)
        
        if returns:
            avg_return = np.mean(returns)
            std_return = np.std(returns)
            sharpe_ratio = avg_return / std_return if std_return > 0 else 0
        else:
            sharpe_ratio = 0
        
        # Generate analysis
        period = f"{len(portfolio_history)} data points"
        
        # Summary
        if total_return > 2:
            summary = f"Excellent performance with {total_return:.3f}% return and {win_rate:.1f}% win rate."
        elif total_return > 0:
            summary = f"Positive performance with {total_return:.3f}% return, though modest gains."
        elif total_return > -1:
            summary = f"Near break-even performance with {total_return:.3f}% return."
        else:
            summary = f"Underperforming with {total_return:.3f}% loss requiring strategy adjustment."
        
        # Strengths and weaknesses
        strengths = []
        weaknesses = []
        recommendations = []
        
        if win_rate > 70:
            strengths.append(f"High win rate of {win_rate:.1f}% indicates good trade selection")
        elif win_rate < 50:
            weaknesses.append(f"Low win rate of {win_rate:.1f}% suggests poor entry timing")
        
        if max_drawdown < 2:
            strengths.append(f"Low maximum drawdown of {max_drawdown:.2f}% shows good risk control")
        elif max_drawdown > 5:
            weaknesses.append(f"High maximum drawdown of {max_drawdown:.2f}% indicates excessive risk")
        
        if sharpe_ratio > 1:
            strengths.append(f"Strong risk-adjusted returns with Sharpe ratio of {sharpe_ratio:.2f}")
        elif sharpe_ratio < 0:
            weaknesses.append(f"Poor risk-adjusted returns with negative Sharpe ratio")
        
        # Recommendations
        if win_rate < 60:
            recommendations.append("Improve entry criteria to increase win rate")
        if max_drawdown > 3:
            recommendations.append("Implement tighter stop-loss controls to reduce drawdown")
        if avg_profit_per_trade < 0.001:
            recommendations.append("Increase profit targets or reduce trading frequency")
        
        return PerformanceAnalysis(
            period=period,
            total_return=total_return,
            win_rate=win_rate,
            avg_profit_per_trade=avg_profit_per_trade,
            max_drawdown=max_drawdown,
            sharpe_ratio=sharpe_ratio,
            summary=summary,
            strengths=strengths,
            weaknesses=weaknesses,
            recommendations=recommendations
        )
    
    def _identify_trading_patterns(self, session_data: Dict) -> Dict:
        """Identify and describe trading patterns."""
        portfolio_history = session_data.get('portfolio_history', [])
        trades = session_data.get('trades', [])
        
        patterns = {
            'detected_patterns': [],
            'pattern_analysis': {},
            'trend_description': "",
            'volatility_analysis': ""
        }
        
        if not portfolio_history:
            return patterns
        
        # Analyze price movements
        portfolio_values = [p['portfolio_value'] for p in portfolio_history]
        
        # Detect trends
        if len(portfolio_values) > 5:
            recent_trend = np.polyfit(range(len(portfolio_values)), portfolio_values, 1)[0]
            
            if recent_trend > 0.1:
                patterns['detected_patterns'].append('bull_run')
                patterns['trend_description'] = "Strong upward trend detected in portfolio value"
            elif recent_trend < -0.1:
                patterns['detected_patterns'].append('bear_market')
                patterns['trend_description'] = "Downward trend observed in portfolio performance"
            else:
                patterns['detected_patterns'].append('consolidation')
                patterns['trend_description'] = "Portfolio value consolidating in a range"
        
        # Analyze volatility
        if len(portfolio_values) > 3:
            returns = []
            for i in range(1, len(portfolio_values)):
                ret = (portfolio_values[i] - portfolio_values[i-1]) / portfolio_values[i-1]
                returns.append(ret)
            
            volatility = np.std(returns) if returns else 0
            
            if volatility > 0.02:
                patterns['detected_patterns'].append('volatility_spike')
                patterns['volatility_analysis'] = f"High volatility detected ({volatility:.4f}), indicating unstable market conditions"
            elif volatility < 0.005:
                patterns['volatility_analysis'] = f"Low volatility ({volatility:.4f}) suggests stable, range-bound trading"
            else:
                patterns['volatility_analysis'] = f"Moderate volatility ({volatility:.4f}) indicates normal market conditions"
        
        # Analyze trading frequency patterns
        if trades:
            trade_times = [datetime.fromisoformat(t['timestamp'].replace('Z', '+00:00')) for t in trades]
            
            # Check for clustering
            if len(trade_times) > 1:
                time_gaps = [(trade_times[i] - trade_times[i-1]).total_seconds() / 60 for i in range(1, len(trade_times))]
                avg_gap = np.mean(time_gaps)
                
                if avg_gap < 30:
                    patterns['detected_patterns'].append('high_frequency')
                    patterns['pattern_analysis']['trading_frequency'] = "High-frequency trading pattern detected"
                elif avg_gap > 120:
                    patterns['detected_patterns'].append('low_frequency')
                    patterns['pattern_analysis']['trading_frequency'] = "Conservative, low-frequency trading approach"
        
        return patterns
    
    def _generate_market_insights(self, session_data: Dict) -> List[TradingInsight]:
        """Generate actionable market insights."""
        insights = []
        portfolio_history = session_data.get('portfolio_history', [])
        trades = session_data.get('trades', [])
        
        if not portfolio_history:
            return insights
        
        # Analyze recent performance
        if len(portfolio_history) > 10:
            recent_values = [p['portfolio_value'] for p in portfolio_history[-10:]]
            recent_change = (recent_values[-1] - recent_values[0]) / recent_values[0] * 100
            
            if recent_change > 1:
                insights.append(TradingInsight(
                    timestamp=datetime.now(),
                    insight_type='opportunity',
                    priority='medium',
                    title='Strong Recent Performance',
                    description=f'Portfolio has gained {recent_change:.3f}% in recent trading periods',
                    actionable_items=[
                        'Consider taking partial profits',
                        'Monitor for potential reversal signals',
                        'Maintain current strategy momentum'
                    ],
                    confidence=0.8,
                    data_sources=['portfolio_history']
                ))
            elif recent_change < -1:
                insights.append(TradingInsight(
                    timestamp=datetime.now(),
                    insight_type='warning',
                    priority='high',
                    title='Recent Performance Decline',
                    description=f'Portfolio has declined {abs(recent_change):.3f}% in recent periods',
                    actionable_items=[
                        'Review and adjust trading strategy',
                        'Consider reducing position sizes',
                        'Implement stricter stop-loss controls'
                    ],
                    confidence=0.9,
                    data_sources=['portfolio_history']
                ))
        
        # Analyze trading efficiency
        if trades:
            profitable_trades = sum(1 for t in trades if t.get('profit', 0) > 0)
            win_rate = profitable_trades / len(trades) * 100
            
            if win_rate > 75:
                insights.append(TradingInsight(
                    timestamp=datetime.now(),
                    insight_type='performance',
                    priority='low',
                    title='Excellent Trade Selection',
                    description=f'Win rate of {win_rate:.1f}% indicates superior trade selection',
                    actionable_items=[
                        'Continue current entry criteria',
                        'Consider increasing position sizes',
                        'Document successful patterns'
                    ],
                    confidence=0.9,
                    data_sources=['trades']
                ))
            elif win_rate < 40:
                insights.append(TradingInsight(
                    timestamp=datetime.now(),
                    insight_type='warning',
                    priority='critical',
                    title='Poor Trade Selection',
                    description=f'Low win rate of {win_rate:.1f}% requires immediate strategy review',
                    actionable_items=[
                        'Revise entry and exit criteria',
                        'Reduce position sizes until improvement',
                        'Consider switching to paper trading',
                        'Analyze failed trades for patterns'
                    ],
                    confidence=0.95,
                    data_sources=['trades']
                ))
        
        return insights
    
    def _assess_risk_factors(self, session_data: Dict) -> Dict:
        """Assess and describe risk factors."""
        portfolio_history = session_data.get('portfolio_history', [])
        trades = session_data.get('trades', [])
        
        risk_assessment = {
            'overall_risk_level': 'MEDIUM',
            'risk_factors': [],
            'risk_mitigation': [],
            'risk_score': 50,  # 0-100 scale
            'detailed_analysis': ""
        }
        
        if not portfolio_history:
            risk_assessment['overall_risk_level'] = 'UNKNOWN'
            risk_assessment['detailed_analysis'] = "Insufficient data for risk assessment"
            return risk_assessment
        
        risk_score = 50  # Start with medium risk
        risk_factors = []
        mitigation_strategies = []
        
        # Analyze portfolio volatility
        portfolio_values = [p['portfolio_value'] for p in portfolio_history]
        if len(portfolio_values) > 3:
            returns = [(portfolio_values[i] - portfolio_values[i-1]) / portfolio_values[i-1] 
                      for i in range(1, len(portfolio_values))]
            volatility = np.std(returns)
            
            if volatility > 0.03:
                risk_score += 20
                risk_factors.append("High portfolio volatility indicating unstable returns")
                mitigation_strategies.append("Implement position sizing based on volatility")
            elif volatility < 0.01:
                risk_score -= 10
                risk_factors.append("Low volatility may indicate insufficient profit potential")
        
        # Analyze drawdown risk
        peak = portfolio_values[0]
        max_drawdown = 0
        for value in portfolio_values:
            if value > peak:
                peak = value
            drawdown = (peak - value) / peak * 100
            max_drawdown = max(max_drawdown, drawdown)
        
        if max_drawdown > 5:
            risk_score += 25
            risk_factors.append(f"High maximum drawdown of {max_drawdown:.2f}%")
            mitigation_strategies.append("Implement stricter stop-loss controls")
        elif max_drawdown < 1:
            risk_score -= 5
        
        # Analyze trading frequency risk
        if trades:
            session_duration = (datetime.fromisoformat(portfolio_history[-1]['timestamp'].replace('Z', '+00:00')) - 
                              datetime.fromisoformat(portfolio_history[0]['timestamp'].replace('Z', '+00:00')))
            trades_per_hour = len(trades) / max(session_duration.total_seconds() / 3600, 1)
            
            if trades_per_hour > 3:
                risk_score += 15
                risk_factors.append("High trading frequency increases transaction costs and slippage risk")
                mitigation_strategies.append("Reduce trading frequency and focus on higher-quality setups")
        
        # Determine overall risk level
        if risk_score > 80:
            overall_risk = 'CRITICAL'
        elif risk_score > 65:
            overall_risk = 'HIGH'
        elif risk_score > 35:
            overall_risk = 'MEDIUM'
        else:
            overall_risk = 'LOW'
        
        # Generate detailed analysis
        detailed_analysis = f"Risk assessment based on {len(portfolio_history)} data points reveals {overall_risk.lower()} risk conditions. "
        if risk_factors:
            detailed_analysis += f"Key concerns include: {', '.join(risk_factors[:2])}. "
        if mitigation_strategies:
            detailed_analysis += f"Recommended mitigation: {mitigation_strategies[0]}."
        
        risk_assessment.update({
            'overall_risk_level': overall_risk,
            'risk_factors': risk_factors,
            'risk_mitigation': mitigation_strategies,
            'risk_score': min(100, max(0, risk_score)),
            'detailed_analysis': detailed_analysis
        })
        
        return risk_assessment
    
    def _generate_strategic_recommendations(self, session_data: Dict) -> List[str]:
        """Generate strategic recommendations based on analysis."""
        recommendations = []
        portfolio_history = session_data.get('portfolio_history', [])
        trades = session_data.get('trades', [])
        
        if not portfolio_history:
            return ["Execute trades to generate data for strategic analysis"]
        
        # Performance-based recommendations
        initial_value = portfolio_history[0]['portfolio_value']
        final_value = portfolio_history[-1]['portfolio_value']
        total_return = ((final_value - initial_value) / initial_value) * 100
        
        if total_return > 2:
            recommendations.append("Strong performance suggests current strategy is effective - consider scaling up position sizes")
        elif total_return < -1:
            recommendations.append("Negative returns indicate strategy needs adjustment - review entry/exit criteria")
        
        # Trading frequency recommendations
        if trades:
            session_duration = (datetime.fromisoformat(portfolio_history[-1]['timestamp'].replace('Z', '+00:00')) - 
                              datetime.fromisoformat(portfolio_history[0]['timestamp'].replace('Z', '+00:00')))
            trades_per_hour = len(trades) / max(session_duration.total_seconds() / 3600, 1)
            
            if trades_per_hour > 2:
                recommendations.append("High trading frequency detected - consider more selective entry criteria to improve trade quality")
            elif trades_per_hour < 0.5:
                recommendations.append("Low trading frequency - consider more aggressive thresholds or additional trading pairs")
        
        # Risk management recommendations
        portfolio_values = [p['portfolio_value'] for p in portfolio_history]
        if len(portfolio_values) > 3:
            returns = [(portfolio_values[i] - portfolio_values[i-1]) / portfolio_values[i-1] 
                      for i in range(1, len(portfolio_values))]
            volatility = np.std(returns)
            
            if volatility > 0.02:
                recommendations.append("High volatility detected - implement dynamic position sizing based on market conditions")
        
        # Diversification recommendations
        if trades:
            pairs_traded = set(t.get('pair', 'Unknown') for t in trades)
            if len(pairs_traded) == 1:
                recommendations.append("Consider diversifying across multiple trading pairs to reduce concentration risk")
        
        return recommendations[:5]  # Limit to top 5 recommendations
    
    def _extract_key_insights(self, session_data: Dict) -> List[str]:
        """Extract key insights from the trading session."""
        insights = []
        portfolio_history = session_data.get('portfolio_history', [])
        trades = session_data.get('trades', [])
        
        if not portfolio_history:
            return ["No trading data available for insight generation"]
        
        # Performance insights
        initial_value = portfolio_history[0]['portfolio_value']
        final_value = portfolio_history[-1]['portfolio_value']
        total_return = ((final_value - initial_value) / initial_value) * 100
        
        insights.append(f"Portfolio {'gained' if total_return > 0 else 'lost'} {abs(total_return):.3f}% during this session")
        
        # Trading insights
        if trades:
            profitable_trades = sum(1 for t in trades if t.get('profit', 0) > 0)
            win_rate = profitable_trades / len(trades) * 100
            insights.append(f"Achieved {win_rate:.1f}% win rate across {len(trades)} trades")
            
            # Best and worst trades
            if len(trades) > 1:
                profits = [t.get('profit', 0) for t in trades]
                best_profit = max(profits)
                worst_profit = min(profits)
                insights.append(f"Best trade: +${best_profit:.2f}, Worst trade: ${worst_profit:.2f}")
        
        # Market condition insights
        if len(portfolio_history) > 10:
            recent_volatility = np.std([p['portfolio_value'] for p in portfolio_history[-10:]])
            if recent_volatility > 1:
                insights.append("High recent volatility suggests active market conditions")
            else:
                insights.append("Low recent volatility indicates stable market environment")
        
        return insights
    
    def _create_narrative_summary(self, session_data: Dict) -> str:
        """Create a comprehensive narrative summary of the session."""
        portfolio_history = session_data.get('portfolio_history', [])
        trades = session_data.get('trades', [])
        
        if not portfolio_history:
            return "This trading session contains no portfolio data to analyze. Consider running a longer session to generate meaningful insights."
        
        # Build narrative components
        narrative_parts = []
        
        # Opening
        start_time = datetime.fromisoformat(portfolio_history[0]['timestamp'].replace('Z', '+00:00'))
        end_time = datetime.fromisoformat(portfolio_history[-1]['timestamp'].replace('Z', '+00:00'))
        duration = end_time - start_time
        
        narrative_parts.append(f"This trading session spanned {duration.total_seconds()/3600:.1f} hours, "
                             f"from {start_time.strftime('%H:%M')} to {end_time.strftime('%H:%M')}.")
        
        # Performance narrative
        initial_value = portfolio_history[0]['portfolio_value']
        final_value = portfolio_history[-1]['portfolio_value']
        total_return = ((final_value - initial_value) / initial_value) * 100
        
        if total_return > 1:
            narrative_parts.append(f"The session was notably successful, generating a {total_return:.3f}% return "
                                 f"and growing the portfolio from ${initial_value:.2f} to ${final_value:.2f}.")
        elif total_return > 0:
            narrative_parts.append(f"The session achieved modest gains with a {total_return:.3f}% return, "
                                 f"demonstrating steady progress in portfolio growth.")
        elif total_return > -0.5:
            narrative_parts.append(f"The session resulted in minimal changes with a {total_return:.3f}% return, "
                                 f"suggesting stable but unremarkable market conditions.")
        else:
            narrative_parts.append(f"The session faced challenges with a {total_return:.3f}% loss, "
                                 f"highlighting the need for strategy refinement.")
        
        # Trading activity narrative
        if trades:
            num_trades = len(trades)
            profitable_trades = sum(1 for t in trades if t.get('profit', 0) > 0)
            win_rate = profitable_trades / num_trades * 100
            
            narrative_parts.append(f"Trading activity included {num_trades} executed trades with a {win_rate:.1f}% success rate.")
            
            if win_rate > 70:
                narrative_parts.append("The high win rate demonstrates excellent trade selection and timing.")
            elif win_rate < 50:
                narrative_parts.append("The below-average win rate suggests room for improvement in entry criteria.")
        else:
            narrative_parts.append("No trades were executed during this session, indicating either stable market conditions "
                                 "or overly conservative trading parameters.")
        
        # Risk and volatility narrative
        portfolio_values = [p['portfolio_value'] for p in portfolio_history]
        if len(portfolio_values) > 3:
            returns = [(portfolio_values[i] - portfolio_values[i-1]) / portfolio_values[i-1] 
                      for i in range(1, len(portfolio_values))]
            volatility = np.std(returns)
            
            if volatility > 0.02:
                narrative_parts.append(f"Portfolio volatility was elevated at {volatility:.4f}, "
                                     "indicating dynamic market conditions that required active management.")
            else:
                narrative_parts.append(f"Portfolio volatility remained controlled at {volatility:.4f}, "
                                     "reflecting stable market conditions and effective risk management.")
        
        # Conclusion
        if total_return > 0 and trades and (profitable_trades / len(trades)) > 0.6:
            narrative_parts.append("Overall, this session demonstrates the effectiveness of the current trading strategy "
                                 "and suggests continued application with potential for scaling.")
        elif total_return < 0 or (trades and (profitable_trades / len(trades)) < 0.5):
            narrative_parts.append("This session highlights areas for improvement in the trading strategy, "
                                 "particularly in trade selection and risk management.")
        else:
            narrative_parts.append("This session provides valuable data for strategy refinement and "
                                 "establishes a baseline for future performance comparison.")
        
        return " ".join(narrative_parts)
    
    def generate_daily_summary(self, session_dirs: List[str]) -> str:
        """Generate a comprehensive daily summary across multiple sessions."""
        if not session_dirs:
            return "No trading sessions found for daily summary generation."
        
        # Analyze all sessions
        all_analyses = []
        for session_dir in session_dirs:
            analysis = self.analyze_trading_session(session_dir)
            if 'error' not in analysis:
                all_analyses.append(analysis)
        
        if not all_analyses:
            return "No valid trading data found for daily summary."
        
        # Generate comprehensive summary
        summary_parts = []
        
        # Header
        summary_parts.append("üìä DAILY TRADING SUMMARY")
        summary_parts.append("=" * 50)
        summary_parts.append(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        summary_parts.append(f"Sessions Analyzed: {len(all_analyses)}")
        summary_parts.append("")
        
        # Aggregate performance
        total_sessions = len(all_analyses)
        profitable_sessions = sum(1 for a in all_analyses 
                                if a['performance_analysis']['total_return'] > 0)
        
        summary_parts.append("üéØ OVERALL PERFORMANCE")
        summary_parts.append(f"Profitable Sessions: {profitable_sessions}/{total_sessions} "
                           f"({profitable_sessions/total_sessions*100:.1f}%)")
        
        # Best and worst sessions
        best_session = max(all_analyses, key=lambda x: x['performance_analysis']['total_return'])
        worst_session = min(all_analyses, key=lambda x: x['performance_analysis']['total_return'])
        
        summary_parts.append(f"Best Session: {best_session['session_id']} "
                           f"({best_session['performance_analysis']['total_return']:.3f}%)")
        summary_parts.append(f"Worst Session: {worst_session['session_id']} "
                           f"({worst_session['performance_analysis']['total_return']:.3f}%)")
        summary_parts.append("")
        
        # Key insights
        summary_parts.append("üí° KEY INSIGHTS")
        all_insights = []
        for analysis in all_analyses:
            all_insights.extend(analysis['key_insights'])
        
        # Show top insights
        for insight in all_insights[:5]:
            summary_parts.append(f"‚Ä¢ {insight}")
        summary_parts.append("")
        
        # Strategic recommendations
        summary_parts.append("üéØ STRATEGIC RECOMMENDATIONS")
        all_recommendations = []
        for analysis in all_analyses:
            all_recommendations.extend(analysis['strategic_recommendations'])
        
        # Deduplicate and show top recommendations
        unique_recommendations = list(set(all_recommendations))
        for rec in unique_recommendations[:5]:
            summary_parts.append(f"‚Ä¢ {rec}")
        summary_parts.append("")
        
        # Risk assessment
        risk_levels = [a['risk_assessment']['overall_risk_level'] for a in all_analyses]
        high_risk_sessions = sum(1 for r in risk_levels if r in ['HIGH', 'CRITICAL'])
        
        summary_parts.append("üõ°Ô∏è RISK ASSESSMENT")
        summary_parts.append(f"High Risk Sessions: {high_risk_sessions}/{total_sessions}")
        if high_risk_sessions > total_sessions * 0.5:
            summary_parts.append("‚ö†Ô∏è Elevated risk levels detected - consider reducing position sizes")
        else:
            summary_parts.append("‚úÖ Risk levels within acceptable parameters")
        
        return "\n".join(summary_parts)

def main():
    """Test the enhanced NLP analyzer."""
    analyzer = EnhancedNLPAnalyzer()
    
    print("ü§ñ Enhanced NLP Analysis Test")
    print("=" * 50)
    
    # Find latest session
    data_dir = Path("data")
    session_dirs = []
    for pattern in ["extended_validation_*", "aggressive_test_*", "simple_pair_monitor_*"]:
        session_dirs.extend(data_dir.glob(pattern))
    
    if session_dirs:
        latest_session = max(session_dirs, key=lambda x: x.stat().st_mtime)
        print(f"üìÅ Analyzing: {latest_session.name}")
        
        # Perform analysis
        analysis = analyzer.analyze_trading_session(str(latest_session))
        
        if 'error' not in analysis:
            print(f"\nüìã SESSION SUMMARY:")
            print(analysis['session_summary'])
            
            print(f"\nüìä PERFORMANCE ANALYSIS:")
            perf = analysis['performance_analysis']
            print(f"Total Return: {perf['total_return']:.3f}%")
            print(f"Win Rate: {perf['win_rate']:.1f}%")
            print(f"Summary: {perf['summary']}")
            
            print(f"\nüí° KEY INSIGHTS:")
            for insight in analysis['key_insights']:
                print(f"‚Ä¢ {insight}")
            
            print(f"\nüéØ RECOMMENDATIONS:")
            for rec in analysis['strategic_recommendations']:
                print(f"‚Ä¢ {rec}")
            
            print(f"\nüìñ NARRATIVE SUMMARY:")
            print(analysis['narrative_summary'])
        else:
            print(f"‚ùå Error: {analysis['error']}")
    else:
        print("‚ùå No trading sessions found")

if __name__ == "__main__":
    main()